# Telegram-бот для аналитики по базе данных на основе задач на естественном языке

Бот принимает запросы на естественном языке и на их основе выполняет запросы 
к базе данных, чтобы получить ответ. Принимаются запросы, на которые ответ может
быть сформулирован в виде одного числа.

---

## Запуск проекта локально

#### Требования
- Docker (проверялось на актуальных версиях)
- Docker Compose v2

#### Шаги

```bash
# Клонируем репозиторий
git clone https://github.com/Dev-AlexB/tg_bot_ai.git
cd tg_bot_ai

# Создаём файл окружения
cp env_example .env
```
Далее в .env необходимо заполнить `BOT_TOKEN` (его нужно получить у **@BotFather**).
```bash
# Запускаем сервисы
docker compose up --build -d
```

После запуска сервисов нужно подключиться к контейнеру и скачать модель,
дождаться окончания скачивания.

```bash
docker exec -it ollama ollama pull qwen2.5:3b
```
После этого лучше перезапустить сервисы 
(при первом старте без модели может быть ошибка на этапе прогрева модели).

Telegram-бот начнёт принимать сообщения

Остановка:
```bash
docker compose down
```
---

## Архитектура проекта

Общая схема:

```
Telegram
   ↓
Bot Handler
   ↓
Query Processor
   ↓
LLM Service
   ↓
SQL Validator
   ↓
Database (через ORM / DB driver)
```

### Основные компоненты

- **Bot Handler** принимает сообщения от Telegram, выполняет первичную валидацию
входных данных и передаёт запрос в слой обработки.

- **Query Processor** - оркестратор запроса. Управляет всем жизненным циклом обработки:
   - передаёт текстовый запрос в LLM;
   - валидирует ответ;
   - инициирует выполнение SQL;
   - проверяет результат и формирует ответ пользователю.

- **LLM Service** инкапсулирует взаимодействие с LLM:
  - формирует системный промпт;
  - отправляет запрос модели;
  - проверяет ответ на соответствие ожидаемому JSON-формату.

- **LLM** используется исключительно для интерпретации пользовательского запроса
и генерации структурированного описания запроса (SQL).
Не имеет прямого доступа к базе данных и не участвует в выполнении запросов.

- **SQL Validator** выполняет дополнительную проверку SQL, сгенерированного LLM:
  - разрешены только допустимые типы операций (например, SELECT);
  - запрещены опасные конструкции;
  - проверяется соответствие структуре базы данных.

- **ORM / DB layer** отвечает за безопасное выполнение валидированного 
SQL-запроса и получение результата из базы данных.
ORM не участвует в интерпретации запроса и не формирует SQL самостоятельно.

- **Database** - источник данных.

---

## Преобразование текстовых запросов в запросы к БД

Подход:

1. Пользователь вводит текстовый запрос (на естественном языке)
2. Запрос пользователя перенаправляется LLM в сопровождении системного промпта
3. LLM генерирует ответ в виде JSON
4. JSON валидируется
5. Из JSON извлекается SQL и валидируется дополнительно в целях безопасности
6. Приложение исполняет полученный SQL запрос
7. Результат проверяется на предмет соответствия требованиям (одно число)
8. Бот направляет ответ пользователю
---

## Использование LLM
Промпт направляемый LLM состоит из системного промпта + "Запрос пользователя" + собственно сам текст запроса пользователя.
LLM не хранит контекст, каждый запрос независим.

Системный промпт максимально ограничивает возможности LLM к недетерминированному поведению,
требует генерацию ответа строго по схеме. В системном промпте в терминах предметной области объясняется структура 
базы данных, описываются допустимые SQL операции, логика принятия решений и формат ответа.

LLM применяется **только для интерпретации пользовательского запроса**, она не производит запрос к базе напрямую.
LLM возвращает JSON с ответом структуры:
```json
{
   "status": "ok",
    "sql": "SELECT COUNT(id) AS total_videos FROM videos;",
    "reason": null
}
```
Поле `status` может принимать значения "ok", "cannot_answer", "invalid_question".
В поле `sql` должен прийти SQL запрос сгенерированный LLM.
В поле `reason` LLM пишет причину по которой не смогла сгенерировать SQL запрос.
